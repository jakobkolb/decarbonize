{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of micro model and mean approximation for different imitation prob. terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I run both models for various values of the rewiring probability $\\phi$ and the total factor productivity in the dirty sector $b_d$ and evaluate the results in the following, to see, which effect different interaction terms would have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from plot_routines import plot_routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data into a plotting tool class.\n",
    "micro_path = macro_path = '/home/jakob/Project_Divestment/PyDivestment/output_data/test_output/P1/'\n",
    "micro_selector = 'model = 1'\n",
    "macro_selector = 'model = 2'\n",
    "ptr = plot_routines(micro_path=micro_path, macro_path=macro_path, micro_selector=micro_selector, macro_selector=macro_selector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imitation probability of the form \n",
    "\n",
    "$\\frac{1}{2} ( \\tanh(wi - wj) + 1)$\n",
    "\n",
    "which in the macro model is approximated as\n",
    "\n",
    "$\\frac{1}{2} (wi-wj+1)$\n",
    "\n",
    "leads to astonishingly good agreement of micro model and approximation. See below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = ptr.mk_4plots({'b_d': 1.25, 'phi': .5, 'interaction': 0}, \n",
    "                       upper_limits=[1, 85, 20, 15, 10], \n",
    "                       legend_locations=[4, 7, 7, 7], \n",
    "                       tmax=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet for an imitation probability of the form \n",
    "\n",
    "$\\frac{1}{1 + \\exp(-8 (wi-wj)/(wi + wj))}$\n",
    "\n",
    "as proposed by traulsen et al. 2008, the agreement betwen micro model and approximation becomes significantly worse - even though, the functional form is NOT approximated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = ptr.mk_4plots({'b_d': 1.25, 'phi': .5, 'interaction': 1}, \n",
    "                       upper_limits=[1, 85, 18.5, 15, 10], \n",
    "                       legend_locations=[4, 7, 7, 7],\n",
    "                       tmax=900)\n",
    "figure.savefig('micro_macro_comparison.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for an equally scale invariant but simpler interaction probabiltity such as\n",
    "\n",
    "$\\frac{1}{2} \\frac{wi-wj}{wi+wj}$\n",
    "\n",
    "the discrepancies are even bigger. See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = ptr.mk_4plots({'b_d': 1.25, 'phi': .5, 'interaction': 2}, \n",
    "                       lower_limits=[-.5, 0, 0, 0, 0],\n",
    "                       upper_limits=[.75, 85, 18, 12, 10], \n",
    "                       legend_locations=[4, 7, 7, 7],\n",
    "                       tmax=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It even seems like the imitation probability is too small to allow for propper discrimination of the two investment options. (But in case, this could be fixed by introducing a parameter..)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can systematically check the differences for other values of phi and by calculating the L2 norm between e.g. the x trajectories of micro and macro model results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_data = ptr.micro_mean\n",
    "macro_data = ptr.macro_mean\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "colors = 'bck'\n",
    "interaction_labels = 'ABC'\n",
    "\n",
    "for i, interaction in enumerate([0, 1, 2]):\n",
    "    mid = micro_data.xs(level=['b_d', 'interaction'], key=[1.25, interaction])\n",
    "    mad = macro_data.xs(level=['b_d', 'interaction'], key=[1.25, interaction])\n",
    "    dif = (mid - mad)**2\n",
    "    x = dif[['x']].groupby(level=[0]).sum()\n",
    "    ax.plot(x.index.values, x.values, label=f'interaction: {interaction_labels[i]}', color = colors[i])\n",
    "ax.legend()\n",
    "ax.set_xlabel('$\\phi$')\n",
    "ax.set_ylabel('$L_2$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this confirms, that over almost the entire range of $\\phi$, the first interaction term leads to be best approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13, 3.5))\n",
    "ax1 = fig.add_subplot(141)\n",
    "ptr.mk_opinon_plots({'b_d': 1.25, 'phi': .43, 'interaction': 0}, \n",
    "                   y_limits=[-1, 1],\n",
    "                   legend_location=0,\n",
    "                   ax=ax1,\n",
    "                   legend=False)\n",
    "ax1.annotate('A)', xy=(40, .85))\n",
    "ax2 = fig.add_subplot(142)\n",
    "ptr.mk_opinon_plots({'b_d': 1.25, 'phi': .43, 'interaction': 1}, \n",
    "                   y_limits=[-1, 1],\n",
    "                   legend_location=0,\n",
    "                   ax=ax2,\n",
    "                   legend=False,\n",
    "                   y_ticks=False)\n",
    "ax2.annotate('B)', xy=(40, .85))\n",
    "ax3 = fig.add_subplot(143)\n",
    "ptr.mk_opinon_plots({'b_d': 1.25, 'phi': .43, 'interaction': 2}, \n",
    "                   y_limits=[-1, 1],\n",
    "                   legend_location=0,\n",
    "                   ax=ax3,\n",
    "                   y_ticks=False)\n",
    "ax3.annotate('C)', xy=(40, .85))\n",
    "\n",
    "ax4 = fig.add_subplot(144)\n",
    "\n",
    "colors = 'bck'\n",
    "interaction_labels = 'ABC'\n",
    "\n",
    "for i, interaction in enumerate([0, 1, 2]):\n",
    "    mid = micro_data.xs(level=['b_d', 'interaction'], key=[1.25, interaction])\n",
    "    mad = macro_data.xs(level=['b_d', 'interaction'], key=[1.25, interaction])\n",
    "    dif = (mid - mad)**2\n",
    "    x = dif[['x']].groupby(level=[0]).sum()\n",
    "    ax4.plot(x.index.values, x.values, label=f'interaction: {interaction_labels[i]}', color = colors[i])\n",
    "ax4.legend()\n",
    "ax4.set_xlabel('$\\phi$')\n",
    "ax4.set_ylabel('$L_2$')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('interactions123.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 3))\n",
    "ax1 = fig.add_subplot(131)\n",
    "ptr.mk_opinon_plots({'b_d': 1.25, 'phi': .43, 'interaction': 0}, \n",
    "                   y_limits=[-1, 1],\n",
    "                   legend_location=0,\n",
    "                   ax=ax1,\n",
    "                   legend=False)\n",
    "ax1.annotate('A)', xy=(40, .85))\n",
    "ax2 = fig.add_subplot(132)\n",
    "ptr.mk_opinon_plots({'b_d': 1.25, 'phi': .43, 'interaction': 1}, \n",
    "                   y_limits=[-1, 1],\n",
    "                   legend_location=0,\n",
    "                   ax=ax2,\n",
    "                   legend=False,\n",
    "                   y_ticks=False)\n",
    "ax2.annotate('B)', xy=(40, .85))\n",
    "\n",
    "ax4 = fig.add_subplot(133)\n",
    "\n",
    "colors = 'bck'\n",
    "interaction_labels = 'ABC'\n",
    "\n",
    "for i, interaction in enumerate([0, 1]):\n",
    "    mid = micro_data.xs(level=['b_d', 'interaction'], key=[1.25, interaction])\n",
    "    mad = macro_data.xs(level=['b_d', 'interaction'], key=[1.25, interaction])\n",
    "    dif = (mid - mad)**2\n",
    "    x = dif[['x']].groupby(level=[0]).sum()\n",
    "    ax4.plot(x.index.values, x.values, label=f'interaction: {interaction_labels[i]}', color = colors[i])\n",
    "ax4.legend()\n",
    "ax4.set_xlabel('$\\phi$')\n",
    "ax4.set_ylabel('$L_2$')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('interactions12.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
